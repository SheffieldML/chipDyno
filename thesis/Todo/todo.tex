\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}

%opening
\title{TODO}
\author{Arif}

\begin{document}

\maketitle

I would like to dedicate this thesis to my family and my close friends \dots

\paragraph{Ch:1 Intro}
\begin{enumerate}
 \item Bring the brief goal at the beginning 
 \item Affymatrix image
\end{enumerate}

\paragraph{Ch:2 Pro TFA}
\begin{enumerate}
 \item Update draft
 \item Markov property in appendix 
\end{enumerate}

\paragraph{Ch:3 GP}
\begin{enumerate}
 \item Add Brownian kernel : http://www.biostat.umn.edu/~baolin/teaching/probmods/ipm-ch10.html
 \item Add Cosine kernel % Done
 \item GP properties: Add multiplication % Done
\end{enumerate}

\paragraph{Ch:4 TFA GP}
\begin{enumerate}
 \item Update draft
\end{enumerate}

\paragraph{Ch:5 Clustering}
\begin{enumerate}
 \item Mitochondria
 \item explanation of Pathway analysis
 \item include description of table and figure
 \item describe Figure C.elegans
\end{enumerate}

\paragraph{Ch:6 Conclusion}
\begin{enumerate}
 \item Write
\end{enumerate}

\paragraph{Appendix}
\begin{enumerate}
 \item SVD % DONE
 \item PCA
 \item GP property - Dei 10/166  Gir04.pdf 127  %Done
 \item Markov property in appendix for Chapter 2 % DONE
 \item http://www.robots.ox.ac.uk/~mebden/reports/GPtutorial.pdf
 \item ThesisMalte\_[0].pdf %DONE
\end{enumerate}



\paragraph{Overall}
\begin{enumerate}
 \item Acknowledgement %Done
 \item Check Figure/Equation font
 \item Check Figure explanation
 \item Notation as  %Done %http://www.doc.ic.ac.uk/~mpd37/theses/2014_msc_junwei-ng.pdf
 \item UCL-b2 Cholesky decompositions %Done
 \item Bayesian parametric modelling Gir04.pdf 24 % DONE
 \item Transcriptome http://www.nature.com/scitable/definition/transcriptome-296
\end{enumerate}


Machine learning is a joint field of artificial intelligence and modern statistics, mostly focused on the design and development of models, algorithms and techniques that allow computers to extract information automatically by some learning process from data. The structure learned from data can be described by a statistical model. Gaussian process models are well known families of stochastic processes for modelling data observed over time, space or both. Data modelling with Gaussian process is the state-of-the-art technique in the wider community, from robotics (\cite{Deisenroth:2014}) to genomics (\cite{Topa:2015}), from astronomy (\cite{Rajpaul:2015}) to  meteorology (\cite{Chen:2014}).  Gaussian processes models are non-parametric, which means the models are developed on an infinite-dimensional parameter space. For a particular learning problem, the parameter space is typically learnt as the set of possible solutions. There are different ways to learn functions. Probabilistic inference is one of the elegant and widely accepted way among them. In the field of machine learning regression is a supervised learning problem, while clustering is an unsupervised learning problem. Regression task is related with making predictions of a continuous output variable at any desired input location, given an input-output training set. Clustering task group a set of observations into subsets (also known as clusters) so that observations in the same cluster shows similarity in some specific sense. Here we set two generic goals for this thesis



\end{document}
